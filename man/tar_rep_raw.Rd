% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tar_rep.R
\name{tar_rep_raw}
\alias{tar_rep_raw}
\title{Batched replication using dynamic branching
(raw version).}
\usage{
tar_rep_raw(
  name,
  command,
  batches = 1,
  reps = 1,
  tidy_eval = targets::tar_option_get("tidy_eval"),
  packages = targets::tar_option_get("packages"),
  library = targets::tar_option_get("library"),
  format = targets::tar_option_get("format"),
  iteration = "list",
  error = targets::tar_option_get("error"),
  memory = targets::tar_option_get("memory"),
  deployment = targets::tar_option_get("deployment"),
  priority = targets::tar_option_get("priority"),
  template = targets::tar_option_get("template"),
  resources = targets::tar_option_get("resources"),
  storage = targets::tar_option_get("storage"),
  retrieval = targets::tar_option_get("retrieval"),
  cue = targets::tar_option_get("cue")
)
}
\arguments{
\item{name}{Character of length 1, name of the target.}

\item{command}{Similar to the \code{command} argument of \code{\link[targets:tar_target]{tar_target()}} except
the object must already be an expression instead of
informally quoted code.
\code{base::expression()} and \code{base::quote()} can produce such objects.}

\item{batches}{Number of batches. This is also the number of dynamic
branches created during \code{tar_make()}.}

\item{reps}{Number of replications in each batch. The total number
of replications is \code{batches * reps}.}

\item{tidy_eval}{Whether to invoke tidy evaluation
(e.g. the \verb{!!} operator from \code{rlang}) as soon as the target is defined
(before \code{tar_make()}). Applies to the \code{command} argument.}

\item{packages}{Character vector of packages to load right before
the target builds. Use \code{tar_option_set()} to set packages
globally for all subsequent targets you define.}

\item{library}{Character vector of library paths to try
when loading \code{packages}.}

\item{format}{Optional storage format for the target's return value.
With the exception of \code{format = "file"}, each target
gets a file in \verb{_targets/objects}, and each format is a different
way to save and load this file.
Possible formats:
\itemize{
\item \code{"file"}: A dynamic file. To use this format,
the target needs to manually identify or save some data
and return a character vector of paths
to the data. Those paths must point to files or directories,
and they must not contain characters \code{|} or \code{*}.
Then, \code{targets} automatically checks those files and cues the
appropriate build decisions if those files are out of date.
\item \code{"rds"}: Default, uses \code{saveRDS()} and \code{readRDS()}. Should work for
most objects, but slow.
\item \code{"qs"}: Uses \code{qs::qsave()} and \code{qs::qread()}. Should work for
most objects, much faster than \code{"rds"}.
\item \code{"fst"}: Uses \code{fst::write_fst()} and \code{fst::read_fst()}.
Much faster than \code{"rds"}, but the value must be
a data frame.
\item \code{"fst_dt"}: Same as \code{"fst"}, but the value is a \code{data.table}.
\item \code{"fst_tbl"}: Same as \code{"fst"}, but the value is a \code{tibble}.
\item \code{"keras"}: Uses \code{keras::save_model_hdf5()} and
\code{keras::load_model_hdf5()}. The value must be a Keras model.
}}

\item{iteration}{Character of length 1, name of the iteration mode
of the target. Choices:
\itemize{
\item \code{"vector"}: branching happens with \code{vectors::vec_slice()} and
aggregation happens with \code{vctrs::vec_c()}.
\item \code{"list"}, branching happens with \verb{[[]]} and aggregation happens with
\code{list()}.
\item \code{"group"}: \code{dplyr::group_by()}-like functionality to branch over
subsets of a data frame. The target's return value must be a data
frame with a special \code{tar_group} column of consecutive integers
from 1 through the number of groups. Each integer designates a group,
and a branch is created for each collection of rows in a group.
See the \code{\link[targets:tar_group]{tar_group()}} function to see how you can
create the special \code{tar_group} column with \code{dplyr::group_by()}.
}}

\item{error}{Character of length 1, what to do if the target
runs into an error. If \code{"stop"}, the whole pipeline stops
and throws an error. If \code{"continue"}, the error is recorded,
but the pipeline keeps going.}

\item{memory}{Character of length 1, memory strategy.
If \code{"persistent"}, the target stays in memory
until the end of the pipeline.
If \code{"transient"}, the target gets unloaded
after every new target completes.
Either way, the target gets automatically loaded into memory
whenever another target needs the value.}

\item{deployment}{Character of length 1, only relevant to
\code{\link[targets:tar_make_clustermq]{tar_make_clustermq()}} and \code{\link[targets:tar_make_future]{tar_make_future()}}. If \code{"remote"},
the target builds on a remote parallel worker. If \code{"local"},
the target builds on the host machine / process managing the pipeline.}

\item{priority}{Numeric of length 1 between 0 and 1. Controls which
targets get deployed first when multiple competing targets are ready
simultaneously. Targets with priorities closer to 1 get built earlier.}

\item{template}{Relevant to \code{\link[targets:tar_make_clustermq]{tar_make_clustermq()}} only.
Named list of values to fill in the \code{clustermq} template file.
Unsupported for now. May be supported in the future if
\code{clustermq} ever supports heterogeneous workers with varying
resource requirements. In the meantime, use the \code{template}
argument of \code{\link[targets:tar_make_clustermq]{tar_make_clustermq()}}.}

\item{resources}{Relevant to \code{\link[targets:tar_make_future]{tar_make_future()}} only.
A named list of resources passed to \code{future::future()} when
defining a new worker.}

\item{storage}{Character of length 1, only relevant to
\code{\link[targets:tar_make_clustermq]{tar_make_clustermq()}} and \code{\link[targets:tar_make_future]{tar_make_future()}}.
If \code{"local"}, the target's return value is sent back to the
host machine and saved locally. If \code{"remote"}, the remote worker
saves the value.}

\item{retrieval}{Character of length 1, only relevant to
\code{\link[targets:tar_make_clustermq]{tar_make_clustermq()}} and \code{\link[targets:tar_make_future]{tar_make_future()}}.
If \code{"local"}, the target's dependencies are loaded on the host machine
and sent to the remote worker before the target builds.
If \code{"remote"}, the remote worker loads the targets dependencies.}

\item{cue}{An optional object from \code{tar_cue()} to customize the
rules that decide whether the target is up to date.}
}
\value{
A list of two targets, one upstream and one downstream.
The upstream one does some work and returns some file paths,
and the downstream target is a pattern that applies \code{format = "file"}.
}
\description{
Shorthand for a pattern that replicates a command
using batches. Batches reduce the number of targets
and thus reduce overhead.
}
\details{
\code{tar_rep()} and \code{tar_rep_raw} each create two targets:
an upstream local stem
with an integer vector of batch ids, and a downstream pattern
that maps over the batch ids. (Thus, each batch is a branch.)
Each batch/branch replicates the command a certain number of times.

Both batches and reps within each batch
are aggregated according to the method you specify
in the \code{iteration} argument. If \code{"list"}, reps and batches
are aggregated with \code{list()}. If \code{"vector"},
then \code{vctrs::vec_c()}. If \code{"group"}, then \code{vctrs::vec_rbind()}.
}
\examples{
\dontrun{
}
}
